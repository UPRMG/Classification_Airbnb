{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from IPython.core.display import Image \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import io\n",
    "from sklearn.preprocessing import Imputer\n",
    "import pydot\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import mode\n",
    "import re\n",
    "from datetime import datetime\n",
    "from lightgbm import plot_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender_bkts = pd.read_csv(\"age_gender_bkts.csv\")\n",
    "countries = pd.read_csv(\"countries.csv\")\n",
    "sessions = pd.read_csv(\"sessions.csv\")\n",
    "test_users = pd.read_csv(\"test_users.csv\")\n",
    "train_users_2 = pd.read_csv(\"train_users_2.csv\")\n",
    "sample_submission_NDF = pd.read_csv(\"sample_submission_NDF.csv\")\n",
    "merged_sessions = pd.read_csv(\"merged_sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date setting - Base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_set_data():\n",
    "    \n",
    "    check = pd.concat([train_users_2, test_users], ignore_index=True)\n",
    "    \n",
    "    check[\"first_affiliate_tracked\"] = check[\"first_affiliate_tracked\"].replace(np.nan, \"untracked\")\n",
    "\n",
    "    check[\"date_account_created\"] = pd.to_datetime(check[\"date_account_created\"], format = \"%Y-%m-%d\")\n",
    "    check[\"timestamp_first_active\"] = pd.to_datetime(check[\"timestamp_first_active\"], format=\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    s_lag = check[\"timestamp_first_active\"] - check[\"date_account_created\"]\n",
    "\n",
    "    check[\"lag_days\"] = s_lag.apply(lambda x : -1 * x.days)\n",
    "    check[\"lag_seconds\"] = s_lag.apply(lambda x : x.seconds)\n",
    "\n",
    "    s_all_check = (check['age'] < 120) & (check['gender'] != '-unknown-')\n",
    "\n",
    "    check['faithless_sign'] = s_all_check.apply(lambda x : 0 if x == True else 1)\n",
    "    \n",
    "    pre_age = check.drop(\"date_first_booking\",axis = 1)\n",
    "    \n",
    "    pre_age['date_account_created_y'] = pre_age[\"date_account_created\"].apply(lambda x : x.year)\n",
    "    pre_age['date_account_created_m'] = pre_age[\"date_account_created\"].apply(lambda x : x.month)\n",
    "    pre_age['date_account_created_d'] = pre_age[\"date_account_created\"].apply(lambda x : x.day)\n",
    "\n",
    "    pre_age['timestamp_first_active_y'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.year)\n",
    "    pre_age['timestamp_first_active_m'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.month)\n",
    "    pre_age['timestamp_first_active_d'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.day)\n",
    "\n",
    "    pre_age = pre_age.drop(\"date_account_created\" , axis=1)\n",
    "    pre_age = pre_age.drop(\"timestamp_first_active\" , axis=1)\n",
    "    \n",
    "    return check, pre_age\n",
    "\n",
    "check, pre_age = pre_age_set_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date setting - Base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_predict_data():\n",
    "    \n",
    "    pre_age['age'] = pre_age['age'].fillna(-1)\n",
    "    \n",
    "    pre_age_sub = pre_age.filter(items = ['age', 'country_destination','id'])\n",
    "    pre_age_dum = pre_age.filter(items = ['affiliate_channel', 'affiliate_provider',\n",
    "                                       'first_affiliate_tracked', 'first_browser', 'first_device_type',\n",
    "                                       'language', 'signup_app', 'signup_flow',\n",
    "                                       'signup_method', 'date_account_created_y', 'date_account_created_m',\n",
    "                                       'date_account_created_d', 'timestamp_first_active_y',\n",
    "                                       'timestamp_first_active_m', 'timestamp_first_active_d',\"lag_days\",\"lag_seconds\",\n",
    "                                        \"faithless_sign\" ])\n",
    "    \n",
    "    \n",
    "    pre_age_dum[['date_account_created_y', 'date_account_created_m', 'date_account_created_d', \\\n",
    "             'timestamp_first_active_y','timestamp_first_active_m', \\\n",
    "             'timestamp_first_active_d']] = pre_age_dum[['date_account_created_y', 'date_account_created_m', \\\n",
    "                                                         'date_account_created_d', 'timestamp_first_active_y',  \\\n",
    "                                                         'timestamp_first_active_m', \\\n",
    "                                                         'timestamp_first_active_d']].astype(str)\n",
    "    \n",
    "    \n",
    "    pre_age_dum = pd.get_dummies(pre_age_dum)\n",
    "    pre_age_dum_con = pd.concat([pre_age_dum, pre_age_sub], axis=1)\n",
    "    pre_age_dum_con[\"age\"] = pre_age_dum_con[\"age\"].replace(-1, np.nan)\n",
    "    \n",
    "    pre_age_mission = pre_age_dum_con[pre_age_dum_con[\"age\"].isna()].reset_index()\n",
    "    pre_age_train = pre_age_dum_con[pre_age_dum_con[\"age\"].notna()].reset_index()\n",
    "    \n",
    "    pre_age_mission_test = pre_age_mission.drop(\"index\", axis=1)\n",
    "    pre_age_train_test = pre_age_train.drop(\"index\", axis=1)\n",
    "    \n",
    "    pre_age_mission_test_drop = pre_age_mission_test.drop(['id', 'age', 'country_destination'], axis=1)\n",
    "    pre_age_train_test_drop = pre_age_train_test.drop(['id', 'age', 'country_destination'], axis=1)\n",
    "    \n",
    "    return pre_age_mission_test, pre_age_train_test, pre_age_mission, pre_age_train, \\\n",
    "            pre_age_mission_test_drop, pre_age_train_test_drop\n",
    "    \n",
    "pre_age_mission_test, pre_age_train_test, pre_age_mission, pre_age_train, \\\n",
    "            pre_age_mission_test_drop, pre_age_train_test_drop = pre_age_predict_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_predict_data_cat():\n",
    "    \n",
    "    bins = [0, 15, 25, 35, 60, 9999]\n",
    "    labels = [\"미성년자\", \"청년\", \"중년\", \"장년\", \"노년\"]\n",
    "    cats = pd.cut(pre_age_train['age'], bins, labels=labels)\n",
    "    cats = pd.DataFrame(cats)\n",
    "    \n",
    "    return cats\n",
    "\n",
    "cats = pre_age_predict_data_cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict gender data setting - Only gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen_data = pd.read_csv(\"model_gen_lgb.csv\")\n",
    "\n",
    "def add_gender():\n",
    "    pre_gen_sub = pre_age.filter(items = ['age', 'country_destination', 'id', 'gender'])\n",
    "    pre_gen_dum = pre_age.filter(items = ['affiliate_channel', 'affiliate_provider',\n",
    "                                       'first_affiliate_tracked', 'first_browser', 'first_device_type',\n",
    "                                         'language', 'signup_app', 'signup_flow',\n",
    "                                       'signup_method', 'date_account_created_y', 'date_account_created_m',\n",
    "                                       'date_account_created_d', 'timestamp_first_active_y',\n",
    "                                       'timestamp_first_active_m', 'timestamp_first_active_d'])\n",
    "\n",
    "\n",
    "    pre_gen_dum = pd.get_dummies(pre_gen_dum)\n",
    "    pre_gen_dum_con = pd.concat([pre_gen_dum, pre_gen_sub], axis=1)\n",
    "    pre_gen_dum_con[\"gender\"] = pre_gen_dum_con[\"gender\"].replace(['-unknown-', 'OTHER'], np.nan)\n",
    "\n",
    "    pre_gen_mission = pre_gen_dum_con[pre_gen_dum_con[\"gender\"].isna()].reset_index()\n",
    "    pre_gen_train = pre_gen_dum_con[pre_gen_dum_con[\"gender\"].notna()].reset_index()\n",
    "\n",
    "    pre_gen_mission_test = pre_gen_mission.drop(\"index\", axis=1)\n",
    "    pre_gen_train_test = pre_gen_train.drop(\"index\", axis=1)\n",
    "\n",
    "    pre_gen_mission_test_drop = pre_gen_mission_test.drop(['id', 'age', 'country_destination', \"gender\"], axis=1)\n",
    "    pre_gen_train_test_drop = pre_gen_train_test.drop(['id', 'age', 'country_destination', \"gender\"], axis=1)\n",
    "\n",
    "    pre_gen_mission_test_la = pd.concat([pre_gen_mission_test, pred_gen_data], axis=1)\n",
    "    pre_gen_mission_test_la = pre_gen_mission_test_la.drop(\"gender\", axis=1)\n",
    "    pre_gen_mission_test_la = pre_gen_mission_test_la.rename(columns={\"0\": 'gender'})\n",
    "\n",
    "    last_gen_add = pd.concat([pre_gen_mission_test_la, pre_gen_train_test])\n",
    "\n",
    "    last_gen_add = last_gen_add.filter(items = [\"id\",'gender'])\n",
    "    \n",
    "    return last_gen_add\n",
    "\n",
    "last_gen_add = add_gender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday, Weekend, Day of week data setting - Only Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def holiday():\n",
    "\n",
    "    def get_holidays(year):\n",
    "        response = requests.get(\"https://www.timeanddate.com/calendar/custom.html?year=\"+str(year)+\"\\\n",
    "                                &country=1&cols=3&df=1&hol=25\")\n",
    "        dom = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        trs = dom.select(\"table.cht.lpad tr\")\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"date\", \"holiday\"])\n",
    "        for tr in trs:\n",
    "            datestr = tr.select_one(\"td:nth-of-type(1)\").text\n",
    "            date = datetime.strptime(\"{} {}\".format(year, datestr), '%Y %b %d')\n",
    "            holiday = tr.select_one(\"td:nth-of-type(2)\").text\n",
    "            df.loc[len(df)] = {\"date\" : date, \"holiday\": 1}\n",
    "        return df\n",
    "\n",
    "    holiday_ls = []\n",
    "    for year in range(2009, 2015):\n",
    "        df = get_holidays(year)\n",
    "        holiday_ls.append(df)\n",
    "        holiday_df = pd.concat(holiday_ls)\n",
    "\n",
    "    check = pd.concat([train_users_2, test_users], ignore_index=True)\n",
    "    check[\"timestamp_first_active\"] = check[\"timestamp_first_active\"].apply(lambda x : str(x)[:8])\n",
    "\n",
    "    pre_age_hol = check.filter(items=['id','timestamp_first_active'])\n",
    "\n",
    "    pre_age_hol['week'] = pd.to_datetime(check[\"timestamp_first_active\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    pre_age_hol[\"week\"] = pre_age_hol['week'].dt.weekday\n",
    "    pre_age_hol[\"weekend\"] = pre_age_hol[\"week\"].apply(lambda x : 1 if x>=5 else 0)\n",
    "    pre_age_hol_dum = pd.get_dummies(pre_age_hol['week'])\n",
    "\n",
    "    hdfd = pd.concat([pre_age_hol,pre_age_hol_dum],axis=1)\n",
    "    hdfd = hdfd.drop(\"week\",axis=1)\n",
    "\n",
    "    hdfd = hdfd.rename(columns={0:\"mon\",1:\"tue\",2:\"wed\",3:\"thur\",4:\"fri\",5:\"sat\",6:\"sun\"})\n",
    "\n",
    "    hdfd['timestamp_first_active'] = pd.to_datetime(hdfd[\"timestamp_first_active\"])\n",
    "\n",
    "    add_hol = pd.merge(hdfd, holiday_df, left_on='timestamp_first_active', right_on=\"date\", how=\"left\")\n",
    "\n",
    "    add_hol = add_hol.drop([\"timestamp_first_active\",'date'],axis=1)\n",
    "    add_hol = add_hol.fillna(0)\n",
    "\n",
    "    return add_hol\n",
    "\n",
    "add_hol = holiday()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict age data setting - Merge (age+gender+holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age_data = pd.read_csv(\"model_age_lgb.csv\")\n",
    "# model_age_forest\n",
    "# model_age_xg\n",
    "# model_age_lgb\n",
    "\n",
    "def predict_age_add():\n",
    "    \n",
    "    pre_age_mission_test_la = pd.concat([pre_age_mission_test, pred_age_data], axis=1)\n",
    "    pre_age_mission_test_la = pre_age_mission_test_la.drop(\"age\", axis=1)\n",
    "#     pre_age_mission_test_la[\"0\"] = pre_age_mission_test_la[\"0\"].replace({'age1':25,\"age2\":29,\"age3\":34,\\\n",
    "#                                                                          \"age4\":40,\"age5\":55})\n",
    "\n",
    "    pre_age_mission_test_la[\"0\"] = pre_age_mission_test_la[\"0\"].replace({'미성년자':10,\"청년\":25,\"중년\":35,\\\n",
    "                                                                             \"장년\":45,\"노년\":60})\n",
    "                                                                     \n",
    "    pre_age_mission_test_la = pre_age_mission_test_la.rename(columns={\"0\": 'age'})\n",
    "    \n",
    "    pre_age_train_test_la = pre_age_train_test.drop(\"age\", axis=1)\n",
    "    pre_age_train_test_la['age'] = pre_age_train_test[\"age\"]\n",
    "    \n",
    "    last_age_add = pd.concat([pre_age_mission_test_la, pre_age_train_test_la])\n",
    "    \n",
    "    train_set = train_users_2['id']\n",
    "    train_set = pd.DataFrame(train_set)\n",
    "    test_set = test_users['id']\n",
    "    test_set = pd.DataFrame(test_set)\n",
    "    \n",
    "    last_gen_add_dum = pd.get_dummies(last_gen_add[\"gender\"])\n",
    "    last_gen_add_dum = pd.concat([last_gen_add['id'], last_gen_add_dum], axis=1)\n",
    "\n",
    "    last_train_data = pd.merge(train_set, last_age_add, on=\"id\", how=\"left\")\n",
    "    last_train_data = pd.merge(last_train_data, last_gen_add_dum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    last_test_data = pd.merge(test_set, last_age_add, on=\"id\", how=\"left\")\n",
    "    last_test_data = pd.merge(last_test_data, last_gen_add_dum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    last_train_data = pd.merge(last_train_data, add_hol, on='id', how=\"left\")\n",
    "    last_test_data = pd.merge(last_test_data, add_hol, on='id', how=\"left\")\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_label = le.fit_transform(last_train_data[\"country_destination\"]) \n",
    "    \n",
    "    return last_train_data, last_test_data, y_label, le\n",
    "\n",
    "last_train_data, last_test_data, y_label, le = predict_age_add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data merge and make CSV - Last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_data_setting():\n",
    "    \n",
    "    merged_sessions = pd.read_csv(\"merged_sessions.csv\")\n",
    "    merged_sessions_dum = merged_sessions.drop(['id','secs_elapsed','secs_sum','secs_mean'], axis=1)\n",
    "    merged_sessions_dum = pd.get_dummies(merged_sessions_dum)\n",
    "    ses_dum = pd.concat([merged_sessions_dum,merged_sessions[['id','secs_elapsed','secs_sum','secs_mean']]],axis=1)\n",
    "    \n",
    "    last_train_data_add = pd.merge(last_train_data, ses_dum, on=\"id\", how=\"left\")\n",
    "    last_test_data_add = pd.merge(last_test_data, ses_dum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    ## impute the missing value using median\n",
    "    impute_list = last_test_data_add.columns.tolist()\n",
    "    impute_list.remove(\"id\")\n",
    "    impute_list.remove(\"country_destination\")\n",
    "\n",
    "    imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "\n",
    "    last_train_data_add[impute_list] = imp.fit_transform(last_train_data_add[impute_list])\n",
    "    last_test_data_add[impute_list] = imp.fit_transform(last_test_data_add[impute_list])\n",
    "\n",
    "    last_train_data_add.to_csv(\"last_train_data_add.csv\", index=False)\n",
    "    last_test_data_add.to_csv(\"last_test_data_add.csv\", index=False)\n",
    "    \n",
    "    return last_train_data_add, last_test_data_add\n",
    "\n",
    "last_train_data_add, last_test_data_add = last_data_setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
